#  Kafka

## 一、Kafka入门

### 1.1 概述

​	Kafka是一个分布式的基于发布/订阅模式的消息队列(Message Queue),主要应用于大数据实时处理领域

![image-20220714140930969](http://ybll.vip/md-imgs/202207141409079.png)

### 1.2 消息队列

![image-20220323195357345](http://ybll.vip/md-imgs/202203291302534.png)

#### 1. 消息队列应用场景

**缓存/消峰**、**解耦**和**异步通信**

解耦	可恢复性	缓冲	灵活性以及峰值处理能力	异步通信

#### 2. 消息队列的两种模式

1）点对点模式（一对一，消费者主动拉去数据，消息收到后，消息清除）

![image-20220323200008678](http://ybll.vip/md-imgs/202203291301095.png)

2）发布/订阅模式（一对多，消费者消费数据后，不会清除消息）

![image-20220323195922004](http://ybll.vip/md-imgs/202203291301654.png)

### 1.3 Kafka基础架构

![image-20220323200213792](http://ybll.vip/md-imgs/202203291302111.png)

```
解释：
1.Producer:消息生产者，向Kafka broker发消息的客户端
2.Consumer:消息消费者，向Kafka broker取消息的客户端，每个Consumer都会属于某个Consumer Group
3.Consumer Group:消费者组，由多个消费者组成;消费组内的每个消费者负责消费不同分区的数据，一个分区只能由一个组内的消费者消费;消费者组是逻辑上的一个订阅者
4.Broker:一台Kafka服务器就是一个broker;一个kafka集群有多个broker组成，一个broker可以容纳多个topic
5.Topic:可以理解为一个队列，生产者和消费者都是面向topic的
6.Partition:一个topic可以分布到不同的broker上，一个topic则可以分为多个partition,每个partition都是一个有序的队列
7.Replica:副本，Kafka提供副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower
8.leader:每个分区多个副本的领导者，生产者发送数据，消费者消费数据的对象都是Leader
9.follower:每个分区多个副本的跟随者,实时从leader中同步数据，保持和leader数据的同步,leader发生故障时,某个follower会成为新的leader
```

### 1.4 Kafka入门

#### 1. Kafka安装部署

> 集群规划
>
> ![image-20220714151955943](http://ybll.vip/md-imgs/202207141519998.png)

```bash
#1.解压安装包
tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/
mv kafka_2.12-3.0.0/ kafka

#2.修改配置文件
vim config/server.properties
#输入一下内容
#broker的全局唯一编号，不能重复
broker.id=0
#删除topic功能使能,当前版本此配置默认为true，已从配置文件移除
delete.topic.enable=true
#处理网络请求的线程数量
num.network.threads=3
#用来处理磁盘IO的线程数量
num.io.threads=8
#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400
#接收套接字的缓冲区大小
socket.receive.buffer.bytes=102400
#请求套接字的缓冲区大小
socket.request.max.bytes=104857600
#kafka运行日志存放的路径
log.dirs=/opt/module/kafka/datas
#topic在当前broker上的分区个数
num.partitions=1
#用来恢复和清理data下数据的线程数量
num.recovery.threads.per.data.dir=1
#segment文件保留的最长时间，超时将被删除
log.retention.hours=168
#配置连接Zookeeper集群地址
zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka

#3.配置环境变量
vim /etc/profile.d/my_env.sh
source /etc/profile
xsync kafka/
#4.修改hadoop103,hadoop104中的broker.id=1,2

#5.启动集群,先启动zookeeper,再启动kafka
myzookeeper.sh start #自己写的脚本
#hadoop102,103,104节点均启动
bin/kafka-server-start.sh -daemon config/server.properties
#6.关闭集群
bin/kafka-server-stop.sh stop
```

```shell
#Kafka群起脚本
#!/bin/bash
if [ $# -lt 1 ]
then
	echo "参数数量有误！(start stop)"
	exit
fi
for i in hadoop102 hadoop103 hadoop104
do
case $1 in
start)
	echo "===== 启动 $i KAFKA ====="
	ssh $i /opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties
;;
stop)
	echo "===== 停止 $i KAFKA ====="
        ssh $i /opt/module/kafka/bin/kafka-server-stop.sh stop
;;
*)
	echo "参数输入有误！(start stop)"
	exit
;;
esac
done
```

+ 停止Kafka集群时，一定要等Kafka所有节点进程全部停止后再停止Zookeeper集群。因为Zookeeper集群当中记录着Kafka集群相关信息，Zookeeper集群一旦先停止，Kafka集群就没有办法再获取停止进程的信息，只能手动杀死Kafka进程了。

#### 2. 命令行操作

> + 主题topics命令行操作 `kafka-topics.sh`
>
>   | 参数                                              | 描述                                 |
>   | ------------------------------------------------- | ------------------------------------ |
>   | --bootstrap-server <String: server toconnect to>  | 连接的Kafka Broker主机名称和端口号。 |
>   | --topic <String: topic>                           | 操作的topic名称。                    |
>   | --create                                          | 创建主题。                           |
>   | --delete                                          | 删除主题。                           |
>   | --alter                                           | 修改主题。                           |
>   | --list                                            | 查看所有主题。                       |
>   | --describe                                        | 查看主题详细描述。                   |
>   | --partitions <Integer: # of partitions>           | 设置分区数。                         |
>   | --replication-factor<Integer: replication factor> | 设置分区副本。                       |
>   | --config <String: name=value>                     | 更新系统默认的配置。                 |
>
> + 生产者命令行操作 `kafka-console-producer.sh` 
>
>   | 参数                                             | 描述                                 |
>   | ------------------------------------------------ | ------------------------------------ |
>   | --bootstrap-server <String: server toconnect to> | 连接的Kafka Broker主机名称和端口号。 |
>   | --topic <String: topic>                          | 操作的topic名称。                    |
>
> + 消费者命令行操作 `kafka-console-consumer.sh` 
>
>   | 参数                                             | 描述                                 |
>   | ------------------------------------------------ | ------------------------------------ |
>   | --bootstrap-server <String: server toconnect to> | 连接的Kafka Broker主机名称和端口号。 |
>   | --topic <String: topic>                          | 操作的topic名称。                    |
>   | --from-beginning                                 | 从头开始消费。                       |
>   | --group <String: consumer group id>              | 指定消费者组名称。                   |
>
> +++
>
> + 实操
>
> ```bash
> #查看当前服务器中的所有tipic
> kafka-topics.sh --bootstrap-server hadoop102:9092 --list
> 
> #创建 ybllcodes topic ,分区数 1 , 副本数 3
> kafka-topics.sh --bootstrap-server hadoop102:9092 --create --partitions 1 --replication-factor 3 --topic ybllcodes
> 
> #查看ybllcodes主题详情
> kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic ybllcodes
> [atguigu@hadoop102 ~]$ kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic ybllcodes
> #Topic: ybllcodes	TopicId: -GQ4Eyd6QC-1X1WktXRnnA	PartitionCount: 1	ReplicationFactor: 3	Configs: segment.bytes=1073741824
> #	Topic: ybllcodes	Partition: 0	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0
> 
> 
> #修改分区数（分区数只能增加，不能减少）
> kafka-topics.sh --bootstrap-server hadoop102:9092 --alter --topic ybllcodes --partitions 3
> #再次查看详情
> #Topic: ybllcodes	TopicId: -GQ4Eyd6QC-1X1WktXRnnA	PartitionCount: 3	ReplicationFactor: 3	Configs: segment.bytes=1073741824
> #	Topic: ybllcodes	Partition: 0	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0
> #	Topic: ybllcodes	Partition: 1	Leader: 2	Replicas: 2,1,0	Isr: 2,1,0
> #	Topic: ybllcodes	Partition: 2	Leader: 0	Replicas: 0,2,1	Isr: 0,2,1
> 
> 
> ###########生产者命令行操作  ConsoleProducer进程(jps)
> #指定往 first 主题发送消息
> kafka-console-producer.sh --bootstrap-server hadoop102:9092 --topic first
> 
> ###########消费者命令行操作  ConsoleConsumer进程(jps)
> #指定订阅 first 主题的消息
> kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first
> 
> kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --from-beginning
> ```
>
> +++



## 二、Kafka 生产者

### 2.1 发送消息流程

> 消息发送的过程中，涉及两个线程：main线程 和 Sender线程，以及一个线程共享变量：RecordAccumulator
>
> + main线程中创建了一个双端队列 RecordAccumulator,并将消息放入其中
> + Sender线程不断从RecordAccumulator中拉取消息，发送到 Kafka Broker
>
> ![image-20220718151255631](http://ybll.vip/md-imgs/202207181513194.png)
>
> + 自我描述
>
>   > 
>
> +++
>
> 生产者重要参数列表
>
> | 参数名称                              | 描述                                                         |
> | ------------------------------------- | ------------------------------------------------------------ |
> | bootstrap.servers                     | 生产者连接集群所需的broker地址清单。例如hadoop102:9092,hadoop103:9092,hadoop104:9092，可以设置1个或者多个，中间用逗号隔开。注意这里并非需要所有的broker地址，因为生产者从给定的broker里查找到其他broker信息。 |
> | key.serializer和value.serializer      | 指定发送消息的key和value的序列化类型。一定要写全类名。       |
> | buffer.memory                         | RecordAccumulator缓冲区总大小，默认32m。                     |
> | batch.size                            | 缓冲区一批数据最大值，默认16k。适当增加该值，可以提高吞吐量，但是如果该值设置太大，会导致数据传输延迟增加。 |
> | linger.ms                             | 如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。单位ms，默认值是0ms，表示没有延迟。生产环境建议该值大小为5-100ms之间。 |
> | acks                                  | 0：生产者发送过来的数据，不需要等数据落盘应答。1：生产者发送过来的数据，Leader收到数据后应答。-1（all）：生产者发送过来的数据，Leader+和isr队列里面的所有节点收齐数据后应答。默认值是-1，-1和all是等价的。 |
> | max.in.flight.requests.per.connection | 允许最多没有返回ack的次数，默认为5，开启幂等性要保证该值是 1-5的数字。 |
> | retries                               | 当消息发送出现错误的时候，系统会重发消息。retries表示重试次数。默认是int最大值，2147483647。如果设置了重试，还想保证消息的有序性，需要设置MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1否则在重试此失败消息的时候，其他的消息可能发送成功了。 |
> | retry.backoff.ms                      | 两次重试之间的时间间隔，默认是100ms。                        |
> | enable.idempotence                    | 是否开启幂等性，默认true，开启幂等性。                       |
> | compression.type                      | 生产者发送的所有数据的压缩方式。默认是none，也就是不压缩。 支持压缩类型：none、gzip、snappy、lz4和zstd。 |
>
> +++

### 2.2 API

> idea导入依赖
>
> ```xml
> <dependencies>
>         <dependency>
>             <groupId>org.apache.kafka</groupId>
>             <artifactId>kafka-clients</artifactId>
>             <version>3.0.0</version>
>         </dependency>
> </dependencies>
> ```

+++

#### 2.2.1 异步发送API

> + 不带回调函数
>
> ```java
> public class CustomProducer {
>     public static void main(String[] args) {
>         //0.配置
>         Properties properties = new Properties();
>         //0.1 连接集群
>         properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092");
>         //0.2 指定对应的Key和Value的序列化类型 key.serializer
>         //properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
>         // "org.apache.kafka.common.serialization.StringSerializer");
>         properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, 
>                 StringSerializer.class.getName());
>         properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
>                 StringSerializer.class.getName());
>         //上述两个必须要配置
> 
>         //1.创建kafka生产者对象
>         //""  hello
>         KafkaProducer kafkaProducer = new KafkaProducer<String,String>(properties);
> 
>         //2.发送数据
>         for (int i = 0; i < 5 ; i++){
>             kafkaProducer.send(new ProducerRecord("first","atguigu"+i));
>         }
> 
>         //3.关闭资源
>         kafkaProducer.close();
>     }
> }
> ```
>
> + 带回调函数
>
> ```java
> public class CustomProducerCallback {
>     public static void main(String[] args) {
>         //0.配置
>         Properties properties = new Properties();
>         //0.1 连接集群
>         properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092");
>         //0.2 指定对应的Key和Value的序列化类型 key.serializer
>         properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, 
>                        StringSerializer.class.getName());
>         properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
>                        StringSerializer.class.getName());
>         //上述两个必须要配置
> 
>         //1.创建kafka生产者对象
>         //""  hello
>         KafkaProducer kafkaProducer = new KafkaProducer<String,String>(properties);
> 
>         //2.发送数据
>         for (int i = 0; i < 5 ; i++){
>             ProducerRecord pRecord = new ProducerRecord("first", "atguigu_" + i);
>             kafkaProducer.send(pRecord, new Callback() {
>                 @Override
>                 public void onCompletion(RecordMetadata recordMetadata, 
>                                          Exception e) {
>                     if(e ==null){
>                         System.out.println("value:" + pRecord.value()+
>                                 "==>topic:" +recordMetadata.topic() +
>                                 ",分区:" + recordMetadata.partition());
>                     }
>                 }
>             });
>         }
> 
>         //3.关闭资源
>         kafkaProducer.close();
>     }
> }
> ```
>
> + 回调函数在 producer 收到 `应答ack` 时调用
>
> 

#### 2.2.2 同步发送API

> 一条消息发送后，会阻塞当前线程，直到收到应答ack，再发送另一条消息
>
> + 程序运行结果(黏性分区)
>
>   ![image-20220716114532668](http://ybll.vip/md-imgs/202207161145774.png)
>
> ```java
> public class CustomProducerCallback {
>     public static void main(String[] args) throws ExecutionException, InterruptedException {
>         //0.配置
>         Properties properties = new Properties();
>         //0.1 连接集群
>         properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092");
>         //0.2 指定对应的Key和Value的序列化类型 key.serializer
>         properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, 
>                        StringSerializer.class.getName());
>         properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
>                        StringSerializer.class.getName());
>         //上述两个必须要配置
> 
>         //1.创建kafka生产者对象
>         //""  hello
>         KafkaProducer kafkaProducer = new KafkaProducer<String,String>(properties);
> 
>         //2.发送数据
>         for (int i = 1; i < 11 ; i++){
>             ProducerRecord pRecord = new ProducerRecord("first", "atguigu_" + i);
>             System.out.println("发送"+pRecord.value()+"前");
>             kafkaProducer.send(pRecord, new Callback() {
>                 @Override
>                 public void onCompletion(RecordMetadata recordMetadata,
>                                          Exception e) {
>                     if(e ==null){
>                         System.out.println("value:" + pRecord.value()+
>                                 "==>topic:" +recordMetadata.topic() +
>                                 ",分区:" + recordMetadata.partition());
>                     }
>                 }
>             }).get();
>         }
> 
>         //3.关闭资源
>         kafkaProducer.close();
>     }
> }
> ```
>

+++

### 2.3 生产经验

#### 2.3.1 如何提高吞吐量

> batch size : 批次大小，默认16k
>
> linger.ms : 等待时间，默认0，修改为5-100ms
>
> compression.type : 压缩 snappy
>
> RecordAccumulator : 缓冲区大小，默认32M
>
> +++
>
> 123

#### 2.3.2 数据可靠性

> 1. ack应答机制
>
>    ![image-20220718183443000](http://ybll.vip/md-imgs/202207181834098.png)
>
>    +++
>
>    ![image-20220718183559754](http://ybll.vip/md-imgs/202207181835849.png)
>
>    +++
>
>    说明：
>
>    + Leader维护了一个动态的 `ISR` 集合(集合中保存与leader保持同步的follower + leader 的集合)
>    + 当 isr 集合中的节点都完成数据同步后，Leader才会给 producer 发送 ack
>    + 如果 follower 长时间( `replica.lag.time.max.ms` )未向 leader 同步数据，则会被踢出 isr 
>
>    +++
>
>    总结：
>
>    ![image-20220718184253914](http://ybll.vip/md-imgs/202207181842996.png)
>
> 2. 案例配置
>
> ```java
>  // 1. 创建kafka生产者的配置对象
>         Properties properties = new Properties();
> 
>         // 2. 给kafka配置对象添加配置信息：bootstrap.servers
>         properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
> 
>         // key,value序列化（必须）：key.serializer，value.serializer
>         properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
>                        StringSerializer.class.getName());
>         properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
>                        StringSerializer.class.getName());
> 
>         // 设置acks
>         properties.put(ProducerConfig.ACKS_CONFIG, "all");
> 
>         // 重试次数retries，默认是int最大值，2147483647
>         properties.put(ProducerConfig.RETRIES_CONFIG, 3);
> 
>         // 3. 创建kafka生产者对象
>         KafkaProducer<String, String> kafkaProducer = 
>             new KafkaProducer<String, String>(properties);
> 
>         // 4. 调用send方法,发送消息
>         for (int i = 0; i < 5; i++) {
>             kafkaProducer.send(new ProducerRecord<>("first","atguigu " + i));
>         }
> 
>         // 5. 关闭资源
>         kafkaProducer.close();
> ```

+++

#### 2.3.3 数据去重

> ![image-20220718184548374](http://ybll.vip/md-imgs/202207181845438.png)
>
> +++

##### 幂等性

![image-20220718184727858](http://ybll.vip/md-imgs/202207181847959.png)

+ 配置 `enable.idempotence`  ，设置为true,则为开启幂等性，默认为 true

##### 生产者事务

![image-20220718184850699](http://ybll.vip/md-imgs/202207181848809.png)

说明：

+ kafka有一个存储事务信息的topic , 默认有50个分区
+ 使用事务前，必须先指定一个自定义 `transactional.id` , 由此事务id计算出事务属于哪个分区(事务id的hashcode%50)，该分区的Leader副本所在的 `broker节点` 即为当前事务所对应的 `事务协调器` 节点，由此事务协调器进行事务处理
+ 生产者向 `事务协调器` 请求 pid(幂等性，事务Id不变，请求得到的pid也不变，由此实现多会话数据去重)，得到pid后，在由幂等性原理发送消息
+ 消息发送成功后，producer 向事务协调器发送 commit 请求，事务协调器再往 `事务topic` 中持久化commit请求，然后通知producer
+ 事务协调器还会往接受消息的topic发送commit请求，收到成功回应后，事务协调器往事务topic中持久化事务成功信息，事务结束。

事务流程代码

```java
//事务相关api
// 1初始化事务
void initTransactions();
// 2开启事务
void beginTransaction() throws ProducerFencedException;
// 3在事务内提交已经消费的偏移量（主要用于消费者）
void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,
                              String consumerGroupId) throws ProducerFencedException;
// 4提交事务
void commitTransaction() throws ProducerFencedException;
// 5放弃事务（类似于回滚事务的操作）
void abortTransaction() throws ProducerFencedException;
```

```java
//举例代码        
		//0.配置
        Properties properties = new Properties();
        //0.1 连接集群
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092");
        //0.2 指定对应的Key和Value的序列化类型 key.serializer
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
                StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
                StringSerializer.class.getName());
        //上述两个必须要配置

        //必须指定事务id
        properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,"tran01");
        //1.创建kafka生产者对象
        KafkaProducer kafkaProducer = new KafkaProducer<String,String>(properties);

        //事务相关
        kafkaProducer.initTransactions();
        kafkaProducer.beginTransaction();
        try {
            //2.发送数据
            for (int i = 0; i < 5 ; i++){
                kafkaProducer.send(new ProducerRecord("first","atguigu"+i));
            }
            int i = 1/0;
            kafkaProducer.commitTransaction();
        } catch (Exception e) {
            kafkaProducer.abortTransaction();
            e.printStackTrace();
        }

        //3.关闭资源
        kafkaProducer.close();
```

#### 2.3.4 数据有序和无序

> 数据有序：单分区内有序（有条件）；多分区无序
>
> + 单分区有序条件
>
> ![image-20220718192906359](http://ybll.vip/md-imgs/202207181929472.png)
>
> + 说明
>
>   > 开启幂等性后，kafka集群后缓存最近5个request请求的元数据，根据幂等性的 `SeqNumber` 的单调自增确保分区内的最近5个始终有序

## 三、Kafka Broker

### 3.1 Broker工作流程

#### 3.1.1 Zookeeper 存储的Kafka信息

![image-20220718193711839](http://ybll.vip/md-imgs/202207181937941.png)



#### 3.1.2  工作流程

![image-20220718200004607](http://ybll.vip/md-imgs/202207182000732.png)

说明：

> 1. 123
> 2. 124
> 3. 234

#### 3.1.3 Broker 重要参数

| 参数名称                                | 描述                                                         |
| --------------------------------------- | ------------------------------------------------------------ |
| replica.lag.time.max.ms                 | ISR中的Follower超过该事件阈值(默认30s)未向Leader发送同步数据，则该Follower将被踢出ISR。 |
| auto.leader.rebalance.enable            | 默认是true。 自动Leader Partition 平衡。                     |
| leader.imbalance.per.broker.percentage  | 默认是10%。每个broker允许的不平衡的leader的比率。如果每个broker超过了这个值，控制器会触发leader的平衡。 |
| leader.imbalance.check.interval.seconds | 默认值300秒。检查leader负载是否平衡的间隔时间。              |
| log.segment.bytes                       | Kafka中log日志是分成一块块存储的，此配置是指log日志划分 成块的大小，默认值1G。 |
| log.index.interval.bytes                | 默认4kb，kafka里面每当写入了4kb大小的日志（.log），然后就往index文件里面记录一个索引。 |
| log.retention.hours                     | Kafka中数据保存的时间，默认7天。                             |
| log.retention.minutes                   | Kafka中数据保存的时间，分钟级别，默认关闭。                  |
| log.retention.ms                        | Kafka中数据保存的时间，毫秒级别，默认关闭。                  |
| log.retention.check.interval.ms         | 检查数据是否保存超时的间隔，默认是5分钟。                    |
| log.retention.bytes                     | 默认等于-1，表示无穷大。超过设置的所有日志总大小，删除最早的segment。 |
| log.cleanup.policy                      | 默认是delete，表示所有数据启用删除策略；如果设置值为compact，表示所有数据启用压缩策略。 |
| num.io.threads                          | 默认是8。负责写磁盘的线程数。整个参数值要占总核数的50%。     |
| num.replica.fetchers                    | 副本拉取线程数，这个参数占总核数的50%的1/3                   |
| num.network.threads                     | 默认是3。数据传输线程数，这个参数占总核数的50%的2/3 。       |
| log.flush.interval.messages             | 强制页缓存刷写到磁盘的条数，默认是Max(long) (9223372036854775807)。一般交给系统管理。 |
| log.flush.interval.ms                   | 每隔多久，刷数据到磁盘，默认是null。一般不建议修改，交给系统自己管理。 |

### 3.2 生产经验（后续补充）

#### 3.2.1 服役新节点

#### 3.2.2 退役旧节点



### 3.3 Kafka 副本

> 1. Kafka副本作用：提高数据可靠性。
> 2. Kafka默认副本1个，生产环境一般配置为2个，保证数据可靠性；太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率。
> 3. Kafka中副本分为：Leader和Follower。Kafka生产者只会把数据发往Leader，然后Follower找Leader进行同步数据。
> 4. Kafka分区中的所有副本统称为AR（Assigned Repllicas）。
>    + AR = ISR + OSR
>      + ISR，表示和Leader保持同步的Follower集合。如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由 `replica.lag.time.max.ms` 参数设定，默认30s。Leader发生故障之后，就会从ISR中选举新的Leader。
>      + OSR，表示Follower与Leader副本同步时，延迟过多的副本。
>
> +++
>
> `Kafka Controller` : kafka集群中有一个broker的Controller会被选举为Controller Leader，负责管理集群broker的上下线、所有的topic的分区副本分配和Leader选举等工作。Controller的信息同步工作是依赖于Zookeeper的。
>
> +++
>
> 故障处理细节
>
> + Follower故障处理细节
>
>   ![img](http://ybll.vip/md-imgs/202207182043039.png)
>
> + Leader故障处理细节
>
>   ![image-20220718204356884](http://ybll.vip/md-imgs/202207182043947.png)
>
> + 说明
>
>   > 关键词：
>   >
>   > **LEO：指的是每个副本最大的offset；**
>   >
>   > **HW：指的是消费者能见到的最大的offset，ISR队列中最小的LEO。**
>   >
>   > （1）follower故障
>   >
>   > follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该**follower的LEO大于等于该Partition的HW**，即follower追上leader之后，就可以重新加入ISR了。
>   >
>   > （2）leader故障
>   >
>   > leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件***\*高于HW的部分截掉\****，然后从新的leader同步数据。
>   >
>   > 注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。

+++

#### 3.3.1 其他后续补充

![image-20220718205321958](http://ybll.vip/md-imgs/202207182053024.png)

### 3.4 文件存储

#### 3.4.1 存储机制

> ![image-20220718205804838](http://ybll.vip/md-imgs/202207182058941.png)
>
> 
>
> +++
>
> + log 和 index 详解
>
>   ![img](http://ybll.vip/md-imgs/202207182110050.png)
>
> + 说明
>
> + 相关参数
>
>   | 参数                     | 描述                                                         |
>   | ------------------------ | ------------------------------------------------------------ |
>   | log.segment.bytes        | Kafka中log日志是分成一块块存储的，此配置是指log日志划分 成块的大小，默认值1G。 |
>   | log.index.interval.bytes | 默认4kb，kafka里面每当写入了4kb大小的日志（.log），然后就往index文件里面记录一个索引。 稀疏索引。 |

#### 3.4.2 清除策略

##### 日志保存时间设置

> 默认保存7天的时间(168h)，可通过参数修改
>
> + ` log.retention.hours` 小时数，最低优先级
> + `log.retention.minutes` 分钟数
> + `log.retention.ms` 毫秒数，最高优先级
> + `log.retention.check.interval.ms` 负责设置检查周期，默认5分钟
>
> +++
>
> 日志（数据）一旦超过了保存时间，该如何处理？
>
> + kafka 提供了两种清理策略 **delete（默认）** 和 **compact**
> + `log.cleanup.policy` 配置项，【delete,compact】

+++

+ log.cleanup.policy=delete ,将过期数据删除

  + 基于时间，默认使用该项，以segment中所有记录的最大时间戳作为该文件的时间戳，其超时后，再删除该segment

  + 基于大小，默认关闭，基本不会使用，超过设置的所有日志的总大小时，删除最早的segment

    > `log.retention.bytes` 默认等于 -1，表示无穷大，关闭基于大小的删除策略

+ compact 日志压缩

  ![image-20220718212643900](http://ybll.vip/md-imgs/202207182126982.png)

### 3.5 高效读写数据(面试)

> + Kafka是分布式集群，采用分区技术，并行度高
>
> + 读数据采用 **稀疏索引** ，可以快速定位需要消费的数据
>
> + 顺序写磁盘
>
>   + Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。
>
> + 页缓存 + 零拷贝技术
>
>   + 自我描述：Kafka读写依靠操作系统内核提供的 `PageCache` （页缓存）功能，消费者拉取数据时，从页缓存中读取数据，然后直接通过网卡（NIC）进行数据传输，不会走应用层，传输效率高
>
>   ![image-20220719192333970](http://ybll.vip/md-imgs/202207191923511.png)

###### 问题：Broker收到的消息存储磁盘，和页缓存的关系？

## 四、Kafka 消费者

+ 消费方式

  ![image-20220719193522734](http://ybll.vip/md-imgs/202207191935821.png)

### 4.1消费者工作流程

#### 4.1.1 总体工作流程

![image-20220719194134368](http://ybll.vip/md-imgs/202207191941469.png)

> 说明：
>
> 1. 生产者 往 Topic 中发送消息，都是发往每个分区的`leader` ,再由leader进行同步其他follower
> 2. 消费者组 消费消息时，也是和Topic中每个分区的 `leader` 进行通信，
>    + 一个消费者可以消费多个分区的数据
>    + 每个分区的数据，只能由一个消费者组中的一个消费者消费
> 3. 每个消费者消费消息的 `offset` 由消费者提交到 `系统Topic` 中保存 — `__consumer_offsets`

#### 4.1.2 消费者组

+ 原理

  > + 消费者组内的每个消费者负责消费不同分区的数据，一个分区只能由一个 `组内消费者` 消费
  > + 消费者组之间互不影响，所有消费者都属于某个消费者组，即 `消费者组是逻辑上的一个订阅者` 
  > + 消费者组的消费者数超过主题Topic的分区数量，则会有一部分消费者会闲置，不会处理该Topic的消息

  +++

+ 初始化流程

  ![image-20220719195626720](http://ybll.vip/md-imgs/202207191956826.png)

  > 说明：
  >
  > 1. 每个Broker节点都有一个消费者协调器（coordinator）,每个消费者组先根据 **` groupid` **（用户指定）求出对应负责该消费者组的 coordinator
  > 2. 该消费者组的每个消费者都发送 `JoinGroup` 请求给对应的 coordinator, coordinator随机选择一个消费者作为`leader` ,并把需要消费的topic情况发送给leader
  > 3. 消费者Leader负责指定消费方案，并把消费方案发送给 `coordinator` ,消费者协调器会把消费方案发送给该组的所有消费者
  > 4. 每个消费者都要和coordinator保持心跳（`默认3s`）,超过 **45s** （`session.timeout.ms`）后，消费者会被移除，并且会触发 **`再平衡` **，若消费者处理消息时长超过 **5min** (`max.poll.interval.ms`) ,也会出发再平衡  -----***面试***

+ 详细消费流程

  ![image-20220719201629870](http://ybll.vip/md-imgs/202207192016975.png)

  > 说明：
  >
  > 1. 消费者组会创建一个网络连接客户端(ConsumerNetworkClient),用于和Broker进行交互
  > 2. 调用sendFetches()方法抓取数据，
  >    + 参数一：Fetch.min.bytes : 默认1Byte,每批次最小抓取大小
  >    + 参数二：Fetch.max.bytes : 默认50M,每批次最大抓取大小
  >    + 参数三：fetch.max.wait.ms : 默认500ms,一批数据 未达到最小值时的超时时间
  > 3. 发送抓取消息请求( `send()方法` )，Broker通过onSuccess()（回调方法），将数据按批次放入队列中
  > 4. 消费者调用从队列中抓取数据，一次拉取的最大消息条数为500条（ `Max.poll.records` ）
  > 5. 处理消息：反序列化 -- 拦截器 -- 处理数据 

  +++

#### 4.1.3 消费者重要参数

| 参数名称                             | 描述                                                         |
| ------------------------------------ | ------------------------------------------------------------ |
| bootstrap.servers                    | 向Kafka集群建立初始连接用到的host/port列表。                 |
| key.deserializer和value.deserializer | 指定接收消息的key和value的反序列化类型。一定要写全类名。     |
| group.id                             | 标记消费者所属的消费者组。                                   |
| enable.auto.commit                   | 默认值为true，消费者会自动周期性地向服务器提交偏移量。       |
| auto.commit.interval.ms              | 如果设置了  enable.auto.commit 的值为true， 则该值定义了消费者偏移量向Kafka提交的频率，默认5s。 |
| auto.offset.reset                    | 当Kafka中没有初始偏移量或当前偏移量在服务器中不存在（如，数据被删除了），该如何处理？ earliest：自动重置偏移量到最早的偏移量。  latest：默认，自动重置偏移量为最新的偏移量。 none：如果消费组原来的（previous）偏移量不存在，则向消费者抛异常。 anything：向消费者抛异常。 |
| offsets.topic.num.partitions         | __consumer_offsets的分区数，默认是50个分区。                 |
| heartbeat.interval.ms                | Kafka消费者和coordinator之间的心跳时间，默认3s。  该条目的值必须小于  session.timeout.ms ，也不应该高于 session.timeout.ms 的1/3。 |
| session.timeout.ms                   | Kafka消费者和coordinator之间连接超时时间，默认45s。超过该值，该消费者被移除，消费者组执行再平衡。 |
| max.poll.interval.ms                 | 消费者处理消息的最大时长，默认是5分钟。超过该值，该消费者被移除，消费者组执行再平衡。 |
| fetch.min.bytes                      | 默认1个字节。消费者获取服务器端一批消息最小的字节数。        |
| fetch.max.wait.ms                    | 默认500ms。如果没有从服务器端获取到一批数据的最小字节数。该时间到，仍然会返回数据。 |
| fetch.max.bytes                      | 默认Default: 52428800（50 m）。消费者获取服务器端一批消息最大的字节数。如果服务器端一批次的数据大于该值（50m）仍然可以拉取回来这批数据，因此，这不是一个绝对最大值。一批次的大小受message.max.bytes （broker config）or max.message.bytes （topic config）影响。 |
| max.poll.records                     | 一次poll拉取数据返回消息的最大条数，默认是500条。            |

### 4.2 消费者API

> + 在消费者API代码中 必须配置消费者组id
> + 命令行启动消费者不填写，会被自动填写随机的消费者组id

+++

+ 消费主题

  ```java
  Properties properties = new Properties();
  
  properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092");
  properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,
                 StringDeserializer.class.getName());
  properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,
                 StringDeserializer.class.getName());
  
  //配置消费者组
  properties.put(ConsumerConfig.GROUP_ID_CONFIG,"test");
  
  //1. 获取消费者对象
  KafkaConsumer<String, String> consumer = 
      new KafkaConsumer<String, String>(properties);
  
  //2. 订阅topic
  Collection<String> topic = new ArrayList<>();
  topic.add("first");
  consumer.subscribe(topic);
  
  //3.拉取数据打印
  while (true){
  	ConsumerRecords<String, String> poll = consumer.poll(Duration.ofSeconds(5));
      for (ConsumerRecord<String, String> cRecord : poll) {
          String value = cRecord.value();
          String topic_num = cRecord.topic();
          long offset = cRecord.offset();
          System.out.println("分区:"+ topic_num + 
                             ", 数据:" + value +
                             ", 偏移量:" + offset);
      }
  }
  ```

+ 消费分区

  ```java
  // 配置消费者组（必须），名字可以任意起
          properties.put(ConsumerConfig.GROUP_ID_CONFIG,"test");
  
          KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
  
          // 消费某个主题的某个分区数据
          ArrayList<TopicPartition> topicPartitions = new ArrayList<>();
          topicPartitions.add(new TopicPartition("first", 0));
          kafkaConsumer.assign(topicPartitions);
  
          while (true){
  
              ConsumerRecords<String, String> consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));
  
              for (ConsumerRecord<String, String> consumerRecord : consumerRecords) {
                  System.out.println(consumerRecord);
              }
          }
  
  ```

+ 消费者组消费

  > 

### 4.3 分区分配及再平衡

#### 4.3.1 Range

![image-20220720194953166](http://ybll.vip/md-imgs/202207201949287.png)

+ 说明

  > 7个分区，3个消费者
  >
  > + 第一个消费者启动，0-6
  > + 第二个消费者启动，0，1，2，3  ---- 4，5，6
  > + 第三个消费者启动，0，1，2 ---- 3，4 ---- 5，6
  > + 关闭一个消费者，0，1，2，3 ---- 4，5，6

#### 4.3.2 RoundRobin

```java
properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG,
               RoundRobinAssignor.class.getName());
```

![image-20220720195429781](http://ybll.vip/md-imgs/202207201954886.png)

+ 说明

  > 7个分区，3个消费者
  >
  > + 第一个消费者启动，0-6
  > + 第二个消费者启动，0，2，4，6  ---- 1，3，5
  > + 第三个消费者启动，0，3，6 ---- 1，4 ---- 2，5
  > + 关闭一个消费者，？

+++

#### 4.3.3 Sticky

> **粘性分区定义：**
>
> 可以理解为分配的结果带有**粘性的**。即在执行一次新的分配之前，考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。Kafka从0.11.x版本开始引入这种分配策略，首先会尽量均衡的放置分区到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分区不变化。
>
> ```java
> // 修改分区分配策略
> properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG,
>                StickyAssignor.class.getName());
> ```
>
> 7个分区，3个消费者
>
> + 第一个消费者启动，0-6
> + 第二个消费者启动，0，1，2，3  ---- 4，5，6
> + 第三个消费者启动，0，1，2 ---- 4，5 ---- 3，6
> + 关闭第一个消费者，4，5，0，2 ---- 3，1，6

+++

### 4.3 offset位移（后续补充）



## 五、Kafka-Eagle监控

```bash
# 关闭集群
mykafka.sh stop

#修改启动命令
vim /opt/module/kafka/bin/kafka-server-start.sh
	export KAFKA_HEAP_OPTS="-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70"
    export JMX_PORT="9999"
    
#修改后分发给其他节点
```

![image-20220721093940691](http://ybll.vip/md-imgs/202207210939853.png)

+++

```bash
#上传压缩包 kafka-eagle-bin-2.0.8.tar.gz
#解压jar包
tar -zxvf /opt/software/kafka-eagle-bin-2.0.8.tar.gz
#再次解压得到的 jar包 
tar -zxvf efak-web-2.0.8-bin.tar.gz -C /opt/module/
#修改名称
mv efak-web-2.0.8 efak
```

```properties
#修改配置文件 vim conf/system-config.properties

######################################
# multi zookeeper & kafka cluster list
# Settings prefixed with 'kafka.eagle.' will be deprecated, use 'efak.' instead
######################################
efak.zk.cluster.alias=cluster1
cluster1.zk.list=hadoop102:2181,hadoop103:2181,hadoop103:2181/kafka
#cluster2.zk.list=xdn10:2181,xdn11:2181,xdn12:2181

######################################
# kafka offset storage
######################################
cluster1.efak.offset.storage=kafka
#cluster2.efak.offset.storage=zk

######################################
# kafka mysql jdbc driver address
######################################
#配置mysql连接
efak.driver=com.mysql.jdbc.Driver
efak.url=jdbc:mysql://hadoop102:3306/ke?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull
efak.username=root
efak.password=1234
```

```shell
 # 添加环境变量
export EK_HOME=/opt/module/efak
export PATH=$PATH:$KE_HOME/bin
```

```bash
#启动zookeeper集群和Kafka集群

#启动eagle
bin/ke.sh start

#访问 hadoop102:8048
```

![image-20220721095939926](http://ybll.vip/md-imgs/202207210959050.png)

+++

![image-20220721100102250](http://ybll.vip/md-imgs/202207211001544.png)

## 六、Kafka-Kraft模式

